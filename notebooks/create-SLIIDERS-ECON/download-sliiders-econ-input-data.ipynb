{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c487926-08b8-49b2-928d-c95730c36d44",
   "metadata": {},
   "source": [
    "## Notebook for downloading inputs to create SLIIDERS-ECON\n",
    "\n",
    "This notebook contains directions for downloading various input datasets to create the final product for this directory, the **SLIIDERS-ECON** dataset.\n",
    "\n",
    "In general, we will keep the format, file name, and data unaltered, but apply changes when\n",
    "- file name is not human-readable, too long, or is not much informative about the dataset (assign appropriate file names)\n",
    "- file format causes errors (save in a similar file format that is not error-prone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517784ca-badd-41fe-a88c-7b4370260e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ssl\n",
    "import subprocess\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from urllib import request as urequest\n",
    "import zipfile\n",
    "\n",
    "import dask.distributed as dd\n",
    "import pandas as pd\n",
    "from dask_gateway import Gateway\n",
    "from pandas_datareader import wb as dr_wb\n",
    "\n",
    "from sliiders import settings as sset\n",
    "\n",
    "# dask gateway setup\n",
    "gateway = Gateway()\n",
    "image_name = sset.DASK_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc306c-cfca-44dd-9044-0d8c6bf1d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating select directories\n",
    "PWT_DIRECTORY = sset.PATH_PWT_RAW.parent\n",
    "IMF_WEO_DIRECTORY = sset.PATH_IMF_WEO_RAW.parent\n",
    "MPD_DIRECTORY = sset.PATH_MPD_RAW.parent\n",
    "GWDB_DIRECTORY = sset.PATH_GWDB2021_RAW.parent\n",
    "SRTM15PLUS_DIRECTORY = sset.PATH_SRTM15_PLUS.parent\n",
    "MDT_DIRECTORY = sset.PATH_GEOG_MDT_RAW.parent\n",
    "\n",
    "directories_to_create = [\n",
    "    PWT_DIRECTORY,\n",
    "    IMF_WEO_DIRECTORY,\n",
    "    MPD_DIRECTORY,\n",
    "    GWDB_DIRECTORY,\n",
    "    SRTM15PLUS_DIRECTORY,\n",
    "    MDT_DIRECTORY,\n",
    "    sset.DIR_WB_WDI_RAW,\n",
    "    sset.DIR_LITPOP_RAW,\n",
    "    sset.DIR_GEG15_RAW,\n",
    "    sset.DIR_CCI_RAW,\n",
    "    sset.DIR_UN_WPP_RAW,\n",
    "    sset.DIR_UN_AMA_RAW,\n",
    "    sset.DIR_ALAND_STATISTICS_RAW,\n",
    "    sset.DIR_OECD_REGIONS_RAW,\n",
    "    sset.DIR_LANDSCAN_RAW,\n",
    "    sset.DIR_IIASA_PROJECTIONS,\n",
    "    sset.DIR_GEOG_DATUMS_XGM2019e_WGS84,\n",
    "    sset.DIR_GEOG_DATUMS_EGM96_WGS84,\n",
    "    sset.DIR_GADM,\n",
    "]\n",
    "for direc in directories_to_create:\n",
    "    direc.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d4cce-5cc8-4c4d-b3cd-1aaf56e90ce9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fetching raw data from various sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c92a29-bd27-4b1d-838c-7989d7561757",
   "metadata": {},
   "source": [
    "### Penn World Tables 10.0 (PWT 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029359fb-e17a-44c8-a536-4696f7d8c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PWT10.0\n",
    "pwt100_data = pd.read_excel(\"https://www.rug.nl/ggdc/docs/pwt100.xlsx\", sheet_name=2)\n",
    "\n",
    "# PWT10.0 capital details\n",
    "pwt100_data_K = pd.read_excel(\n",
    "    \"https://www.rug.nl/ggdc/docs/pwt100-capital-detail.xlsx\", sheet_name=2\n",
    ")\n",
    "\n",
    "pwt_filenames = [\"pwt_100.xlsx\", \"pwt_K_detail_100.xlsx\"]\n",
    "for i, data in enumerate([pwt100_data, pwt100_data_K]):\n",
    "    data.to_excel(\n",
    "        excel_writer=(PWT_DIRECTORY / pwt_filenames[i]),\n",
    "        sheet_name=\"Sheet1\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08579cb-0c3e-4722-8ae3-944b46297b68",
   "metadata": {},
   "source": [
    "### Maddison Project Dataset (MPD, Maddison Project Database 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb664e52-bdbe-4e2e-b30e-3102fdf8ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "madd = pd.read_excel(\n",
    "    \"https://www.rug.nl/ggdc/historicaldevelopment/maddison/data/mpd2020.xlsx\",\n",
    "    sheet_name=2,\n",
    ")\n",
    "madd.to_excel(\n",
    "    excel_writer=(sset.PATH_MPD_RAW),\n",
    "    index=False,\n",
    "    sheet_name=\"Sheet1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c486f-f4b0-4ad1-849a-542e2a875a11",
   "metadata": {},
   "source": [
    "### World Bank WDI (WB WDI)\n",
    "\n",
    "#### Investment-to-GDP ratio, GDP and GDPpc (nominal and PPP), and Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33996e7-fa36-4496-bda9-1f8a459cde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# country name and iso3 country code information\n",
    "country_info = dr_wb.get_countries()[[\"name\", \"iso3c\"]].rename(\n",
    "    columns={\"name\": \"country\", \"iso3c\": \"ccode\"}\n",
    ")\n",
    "\n",
    "# relevant indicator information for the `dr_wb` module to fetch the variables\n",
    "wbwdi_indicators = [\n",
    "    \"SP.POP.TOTL\",  # population\n",
    "    \"NE.GDI.FTOT.ZS\",  # investment-to-GDP ratio\n",
    "    \"NY.GDP.MKTP.PP.KD\",  # GDP PPP\n",
    "    \"NY.GDP.PCAP.PP.KD\",  # GDP per capita PPP\n",
    "    \"NY.GDP.MKTP.KD\",  # GDP nominal\n",
    "    \"NY.GDP.PCAP.KD\",  # GDP per capita nominal\n",
    "]\n",
    "\n",
    "j = 0\n",
    "for indi in wbwdi_indicators:\n",
    "    indi_info = (\n",
    "        dr_wb.download(indicator=indi, country=\"all\", start=1950, end=2020)\n",
    "        .reset_index()\n",
    "        .astype({\"year\": \"int64\"})\n",
    "        .merge(country_info, on=[\"country\"], how=\"left\")\n",
    "        .set_index([\"ccode\", \"year\"])\n",
    "    )\n",
    "\n",
    "    if j == 0:\n",
    "        j += 1\n",
    "        wbwdi_info = indi_info.copy()\n",
    "    else:\n",
    "        wbwdi_info = wbwdi_info.merge(\n",
    "            indi_info.drop([\"country\"], axis=1),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how=\"outer\",\n",
    "        )\n",
    "\n",
    "# excluding those that have no information and saving the data\n",
    "wb_info_vars = [x for x in wbwdi_info.columns if x != \"country\"]\n",
    "wbwdi_info = wbwdi_info.loc[~pd.isnull(wbwdi_info[wb_info_vars]).all(axis=1), :]\n",
    "wbwdi_info.to_parquet(sset.DIR_WB_WDI_RAW / \"wdi_pop_iy_gdp.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec086b-c676-4690-9f2f-93585172e4d7",
   "metadata": {},
   "source": [
    "#### WB WDI: exchange rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e766dc90-ef52-4f10-ba4c-0fdae8c768c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# country name and iso3 country code information\n",
    "country_info = dr_wb.get_countries()[[\"name\", \"iso3c\"]].rename(\n",
    "    columns={\"name\": \"country\", \"iso3c\": \"ccode\"}\n",
    ")\n",
    "\n",
    "xr_code = \"PA.NUS.FCRF\"\n",
    "xr_wb = dr_wb.download(indicator=xr_code, country=\"all\", start=1950, end=2019)\n",
    "xr_wb = (\n",
    "    xr_wb.reset_index()\n",
    "    .astype({\"year\": \"int64\"})\n",
    "    .merge(country_info, on=[\"country\"], how=\"left\")\n",
    ")\n",
    "(\n",
    "    xr_wb.set_index([\"ccode\", \"year\"])\n",
    "    .rename(columns={xr_code: \"xrate\"})\n",
    "    .to_parquet(sset.DIR_WB_WDI_RAW / \"wdi_xr.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df339e99-0571-4c23-8c7f-6e691b7c39c6",
   "metadata": {},
   "source": [
    "### UN WPP populations (overall and by-population-group data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01b3a3-63ca-4c8e-9d84-8d0ede6c7c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall information\n",
    "un_df = pd.read_csv(\n",
    "    \"https://population.un.org/wpp/Download/Files/\"\n",
    "    \"1_Indicators%20(Standard)/CSV_FILES/WPP2019_TotalPopulationBySex.csv\"\n",
    ")\n",
    "\n",
    "# by_age_group\n",
    "by_age = pd.read_csv(\n",
    "    \"https://population.un.org/wpp/Download/Files/1_Indicators\"\n",
    "    \"%20(Standard)/CSV_FILES/WPP2019_PopulationByAgeSex_Medium.csv\"\n",
    ")\n",
    "\n",
    "# exporting\n",
    "un_df.to_csv(sset.DIR_UN_WPP_RAW / \"UN_WPP2019_TotalPopulation.csv\", index=False)\n",
    "by_age.to_csv(sset.DIR_UN_WPP_RAW / \"UN_WPP2019_Population_by_Age.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb4d29-7c84-49e0-ba3e-4fb7663ecd32",
   "metadata": {},
   "source": [
    "### Åland Island GDP and population (from Statistics and Research Åland or ÅSUB)\n",
    "\n",
    "Note when newer versions are available, old links from ÅSUB will become deprecated; the below links in `ALA_GDP_LINK` and `ALA_POP_LINK` are valid as of 2022-03-29."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b59d8-44fa-4d85-93db-8682b1857e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links\n",
    "ALA_GDP_LINK = (\n",
    "    \"https://www.asub.ax/sites/www.asub.ax/files/attachments/page/nr005en.xls\"\n",
    ")\n",
    "ALA_POP_LINK = (\n",
    "    \"https://www.asub.ax/sites/www.asub.ax/files/attachments/page/alv01_aland_faroe\"\n",
    "    \"_islands_and_greenland_-_an_overview_with_comparable_data.xlsx\"\n",
    ")\n",
    "\n",
    "# datasets read-in\n",
    "ala_gdp = pd.read_excel(ALA_GDP_LINK, header=3)\n",
    "ala_pop = pd.read_excel(ALA_POP_LINK, header=2, sheet_name=\"Population development\")\n",
    "\n",
    "# exporting\n",
    "ala_gdp.to_excel(sset.DIR_ALAND_STATISTICS_RAW / \"aland_gdp.xlsx\", index=False)\n",
    "ala_pop.to_excel(sset.DIR_ALAND_STATISTICS_RAW / \"aland_pop.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe8a00c-5822-467a-80a8-b4b6722eea3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Global Wealth Databook (from Credit Suisse)\n",
    "\n",
    "We download the 2021 vintage (latest as of 2022-03-21)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2a06a-52eb-4f4f-94fd-8d01e9c32042",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_GWDB = (\n",
    "    \"https://www.credit-suisse.com/media/assets/corporate/docs/about-us/research\"\n",
    "    \"/publications/global-wealth-databook-2021.pdf\"\n",
    ")\n",
    "\n",
    "gwr_raw = urequest.urlopen(URL_GWDB)\n",
    "file = open(str(sset.PATH_GWDB2021_RAW), \"wb\")\n",
    "file.write(gwr_raw.read())\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f0b8fa-7c93-4735-9caa-e07777d150a2",
   "metadata": {},
   "source": [
    "### LitPop (Eberenz et al. 2020, Earth Syst. Sci. Data)\n",
    "\n",
    "#### Download Data from the Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed65443-7818-406e-a23a-1f62aba91a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link for downloading the LitPop files\n",
    "link_base = (\n",
    "    \"https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/331316\"\n",
    ")\n",
    "\n",
    "# readme, data, normalized data, and metadata\n",
    "links = [\n",
    "    link_base + \"/_readme_v1_2.txt?sequence=18&isAllowed=y\",\n",
    "    link_base + \"/LitPop_v1_2.tar?sequence=16&isAllowed=y\",\n",
    "    link_base + \"/Lit_Pop_norm_v1.tar?sequence=4&isAllowed=y\",\n",
    "    link_base + \"/_metadata_countries_v1_2.csv?sequence=12&isAllowed=y\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff7328f-8976-4f0c-b981-adff491472c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def litpop_download(link, direc=sset.DIR_LITPOP_RAW):\n",
    "    \"\"\"Given a URL link, downloads (LitPop-related) data from the web and saves it in\n",
    "    the specified local directory. The file name is parsed so that anything after the\n",
    "    string `?sequence` is dropped (e.g., `file.txt?sequence=..` to `file.txt`).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    link : str\n",
    "        URL link for the file online\n",
    "    direc : str or pathlib.Path\n",
    "        directory to store the LitPop datasets\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None, but saves the file downloaded from online to `direc`.\n",
    "\n",
    "    \"\"\"\n",
    "    if type(direc) is str:\n",
    "        direc = Path(direc)\n",
    "\n",
    "    stop = link.find(\"?sequence\")\n",
    "    start = link.rfind(\"/\", 0, stop) + 1\n",
    "    urequest.urlretrieve(link, direc / link[start:stop])\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dfe03b-cc1f-4fa8-a89e-3952b856b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster setup\n",
    "N_CLUSTER = len(links)\n",
    "cluster = gateway.new_cluster(worker_image=image_name, profile=\"micro\")\n",
    "client = cluster.get_client()\n",
    "cluster.scale(N_CLUSTER)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e059a0-cc7f-4193-b682-aeb2155967e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes approximately 20 minutes\n",
    "futures = client.map(litpop_download, links)\n",
    "dd.progress(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39c609-0e3b-4caa-9181-28b4570e097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(0)\n",
    "client.close()\n",
    "cluster.close()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5d6120-d2f8-474a-891e-5b59838d3b11",
   "metadata": {},
   "source": [
    "#### Un-tar and clear storage\n",
    "\n",
    "We only un-tar the regular (not normalized) LitPop data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685d7d9-0c7a-4c99-af5f-639cdd3c618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un-tar\n",
    "regular_litpop = sset.DIR_LITPOP_RAW / \"LitPop_v1_2.tar\"\n",
    "with tarfile.open(regular_litpop) as file:\n",
    "    file.extractall(sset.DIR_LITPOP_RAW)\n",
    "\n",
    "# clear storage for the existing tar file\n",
    "os.remove(regular_litpop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4702790c-75dd-484a-b8e3-0acdf36d5c35",
   "metadata": {},
   "source": [
    "### GEG-15\n",
    "\n",
    "We download 2'30\" GEG15 and unzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3109c6-fa04-406d-9def-21b745f6d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading\n",
    "zip_url = (\n",
    "    \"https://data.humdata.org/dataset/1c9cf1eb-c20a-4a06-8309-9416464af746/\"\n",
    "    \"resource/e321d56d-022e-4070-80ac-f7860646408d/download/gar-exp.zip\"\n",
    ")\n",
    "zip_path = sset.DIR_GEG15_RAW / \"gar-exp.zip\"\n",
    "urequest.urlretrieve(zip_url, zip_path)\n",
    "\n",
    "# unzipping\n",
    "outpath = sset.DIR_GEG15_RAW / zip_path.stem\n",
    "os.makedirs(outpath, exist_ok=True)\n",
    "subprocess.Popen([\"unzip\", f\"{zip_path}\", \"-d\", f\"{outpath}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ef63f-9a5a-40f9-8bd8-c5f33f524616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove zip file (use after unzipping)\n",
    "os.remove(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd9ff7-2b4f-4082-9d4c-0042c2b3ee9f",
   "metadata": {},
   "source": [
    "### Country-level Construction Cost Index from [Lincke and Hinkel (2021, *Earth's Future*)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020EF001965?campaign=woletoc)\n",
    "\n",
    "The accompanying GitHub repository to Lincke and Hinkel (2021) is at [this link](https://github.com/daniellincke/DIVA_paper_migration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb05b93-c8cc-4f9e-9e99-ce5b7d511d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sset.PATH_EXPOSURE_LINCKE, \"wb\") as f:\n",
    "    f.write(\n",
    "        requests.get(\n",
    "            \"https://raw.githubusercontent.com/daniellincke/\"\n",
    "            \"DIVA_paper_migration/master/data/csv/country_input.csv\"\n",
    "        ).content\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a0f73-06b7-4ed9-8ae8-113775265c15",
   "metadata": {},
   "source": [
    "### SRTM 15+\n",
    "\n",
    "We use version 2.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb84251-5e5a-4180-b59c-793fc06dd913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround for urllib request error\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "URL_SRTM15 = \"https://topex.ucsd.edu/pub/srtm15_plus/SRTM15_V2.3.nc\"\n",
    "\n",
    "urequest.urlretrieve(URL_SRTM15, SRTM15PLUS_DIRECTORY / URL_SRTM15.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40116a24-ac34-4a9a-884d-90d2738dda07",
   "metadata": {},
   "source": [
    "### GADM v3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bb86d9-d337-44ad-9a37-d5531f9f6beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_GADM = \"https://biogeo.ucdavis.edu/data/gadm3.6/gadm36_levels_gpkg.zip\"\n",
    "PATH_GADM_ZIP = sset.DIR_GADM / URL_GADM.split(\"/\")[-1]\n",
    "urequest.urlretrieve(URL_GADM, PATH_GADM_ZIP)\n",
    "\n",
    "sset.PATH_GADM.parent.mkdir(exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(PATH_GADM_ZIP, mode=\"r\") as z:\n",
    "    z.extractall(sset.PATH_GADM.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5efcb44-1f60-4377-9d01-e970b918ca5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Further data requiring separate manual instructions\n",
    "\n",
    "In all cases below, `sset` is defined by `from sliiders import settings as sset` as above.\n",
    "\n",
    "### UN Statistics National Accounts (Analysis of Main Aggregates; abbreviated as UN AMA)\n",
    "\n",
    "#### UN AMA nominal (current prices) GDP per capita information\n",
    "\n",
    "1. Travel to this [link](https://unstats.un.org/unsd/snaama/Basic) to get to the UN Statistics National Accounts search page.\n",
    "2. Select all countries and all years available, and select \"GDP, Per Capita GDP - US Dollars\".\n",
    "3. Select \"Export to CSV\", and you will download the file `Results.csv`. Rename this file as `un_snaama_nom_gdppc.csv`. We save this in `sset.DIR_UN_AMA_RAW`.\n",
    "\n",
    "#### UN AMA nominal (current prices) GDP information\n",
    "\n",
    "1. Similar to the nominal GDP per capita information, travel to this [link](https://unstats.un.org/unsd/snaama/Basic) to get to the UN Statistics National Accounts search page.\n",
    "2. Select all countries and all years available, and select \"GDP, at current prices - US Dollars\".\n",
    "3. Select \"Export to CSV\", and you will download the file `Results.csv`. Rename this file as `un_snaama_nom_gdp.csv`. We save this in `sset.DIR_UN_AMA_RAW`.\n",
    "\n",
    "### OECD region-level information\n",
    "\n",
    "#### OECD: population (region-level)\n",
    "1. Go to the following OECD Stat website: link [here](https://stats.oecd.org/)\n",
    "2. On the left, find the header \"Regions and Cities\" and click the \"+\" button.\n",
    "3. From the drop down menu, click on \"Regional Statistics\".\n",
    "4. Again from the drop down menu, click on \"Regional Demography.\"\n",
    "5. Finally, select \"Population by 5-year age groups, small regions TL3.\" Make sure that \"Indicator\" is selected as \"Population, All ages\".\n",
    "6. Download the file by selecting \"Export,\" then \"Text File (CSV).\"\n",
    "7. When a pop-up appears, select \"Default format\" then \"Download.\" Rename the file as `REGION_DEMOGR.csv` (due to it having random-ish numeric parts in the name). Note that this step may take a longer time than others.\n",
    "8. Finally, move the said file to `sset.DIR_OECD_REGIONS_RAW`.\n",
    "\n",
    "#### OECD: GDP (region-level, in millions of constant 2015 PPP USD)\n",
    "1. Similar to the population information, go to the following OECD Stat website: link [here](https://stats.oecd.org/)\n",
    "2. On the left, find the header \"Regions and Cities\" and click the \"+\" button.\n",
    "3. From the drop down menu, click on \"Regional Statistics\".\n",
    "4. Again from the drop down menu, click on \"Regional Economy.\"\n",
    "5. Finally, select \"Gross Domestic Product, Small regions TL3.\" Make sure that \"Measure\" is selected as \"Millions USD, constant prices, constant PPP, base year 2015\".\n",
    "6. Download the file by selecting \"Export,\" then \"Text File (CSV).\"\n",
    "7. When a pop-up appears, select \"Default format\" then \"Download.\" Rename the file as `REGION_ECONOM.csv` (due to it having random-ish numeric parts in the name). Note that this step may take a longer time than others.\n",
    "8. Finally, move the said file to `sset.DIR_OECD_REGIONS_RAW`.\n",
    "\n",
    "### IMF investment-to-GDP ratio, population, and GDP\n",
    "\n",
    "1. Travel to this [link](https://www.imf.org/en/Publications/SPROLLs/world-economic-outlook-databases#sort=%40imfdate%20descending) to get to the World Economic Outlook Databases page.\n",
    "2. Click on the latest \"World Economic Outlook Database\" link on the page; for our purposes, we have used the latest available one, which was \"World Economic Outlook Database, October 2021\" (may be updated in the future).\n",
    "3. Click \"By Countries\", then click \"ALL COUNTRIES\", then click \"CONTINUE\" on the page that says \"Select Countries.\"\n",
    "4. Under the \"NATIONAL ACCOUNTS\" tab, check the following categories:\n",
    "   - Gross domestic product, current prices (U.S. DOLLARS)\n",
    "   - Gross domestic product per capita, current prices (U.S. DOLLARS)\n",
    "   - Gross domestic product per capita, constant prices (PURCHASING POWER PARITY; 2017 INTERNATIONAL DOLLARS)\n",
    "   - Total investment (PERCENT OF GDP)\n",
    "5. Under the \"PEOPLE\" tab, check the category \"Population,\" then click on \"CONTINUE.\"\n",
    "6. Under the tab \"DATE RANGE,\" use the earliest year for \"Start Year\" (1980, in our case), and the latest non-future year for \"End Year\" (2020, in our case).\n",
    "7. Under the tab \"ADVANCED SETTINGS\", click on \"ISO Alpha-3 Code\" for getting country codes. \n",
    "8. Click on \"PREPARE REPORT.\" Then, click on \"DOWNLOAD REPORT.\" Saved data should be in Excel format and be named `WEO_Data.xls`.\n",
    "9. Open the said file on Excel, and re-save it in a preferred format of choice (we chose `.xlsx`); this is because the original file formatting is incompatible with Python and causes the error `ValueError: Excel file format cannot be determined, you must specify an engine manually.`\n",
    "10. In our implementation, we save this file as `sset.PATH_IMF_WEO_RAW`.\n",
    "\n",
    "### World Bank Intercomparison Project 2017 (WB ICP 2017): Construction Cost Index\n",
    "\n",
    "While most World Bank data can be downloaded by using `pandas_datareader.wb`, it seems that variables in WB ICP 2017 - including `1501200:CONSTRUCTION`, which is necessary for SLIIDERS-ECON - cannot be downloaded using the said module (despite being searchable in the module using `pandas_datareader.wb.search`). Therefore, we follow the below manual process for downloading the WB ICP 2017 dataset.\n",
    "1. Use [this link](https://databank.worldbank.org/embed/ICP-2017-Cycle/id/4add74e?inf=n) to access WB ICP 2017 in table format.\n",
    "2. Upon entering the webpage, look to the upper right corner and click on the icon with downward arrow with an underline. This should prompt the download.\n",
    "3. When the download finishes, there should be a `.zip` file called `ICP 2017 Cycle.zip`. Access the `.csv` file whose name ends in `_Data.csv` (there should be two files in the `.zip` file, the other being a file whose name ends in `_Series - Metadata.csv`).\n",
    "4. Save that `.csv` file as `sset.PATH_EXPOSURE_WB_ICP`.\n",
    "\n",
    "### IIASA and OECD models' GDP and population projections (2010-2100, every 5 years)\n",
    "\n",
    "1. Go to the following IIASA SSP Database website: link [here](https://tntcat.iiasa.ac.at/SspDb); you may need to register and create your log-in.\n",
    "2. In the above tabs, there is a tab called \"Download\"; click on it.\n",
    "3. Under \"SSP Database Version 2 Downloads (2018)\" and under the sub-header \"Basic Elements\", there is a download link for `SspDb_country_data_2013-06-12.csv.zip`. Click and download the said `.zip` file.\n",
    "4. Extract and save the `SspDb_country_data_2013-06-12.csv`. Again, for our purposes, we save this in `sset.DIR_IIASA_PROJECTIONS`.\n",
    "\n",
    "### LandScan 2019\n",
    "\n",
    "1. To download this dataset, you need to first apply for an Oak Ridge National Laboratory account (link [here](https://landscan.ornl.gov/user/apply)).\n",
    "2. After having gained access, go to the said website, click on \"DOWNLOAD\" -> \"LandScan Datasets\" -> \"Continue to download\" next to LandScan 2019.\n",
    "3. Click on \"By downloading LandScan 2019 I agree to the above terms\" in the following webpage; this will download the file `LandScan Global 2019.zip`. We save this in `sset.DIR_LANDSCAN_RAW`.\n",
    "\n",
    "### Global geoids, based on select Earth Gravitational Models (EGMs)\n",
    "1. Go to the following International Centre for Global Earth Models (ICGEM) website (link [here](http://icgem.gfz-potsdam.de/calcgrid)) to reach the page \"Calculation of Gravity Field Functionals on Ellipsoidal Grids\".\n",
    "2. Under **Model Selection**, select `XGM2019e_2159`.\n",
    "3. Under **Functional Selection**, select `geoid`.\n",
    "4. Under **Grid selection**, there's a **Grid Step [°]** option. Change the value to **0.05**. Also, make sure that the **Reference System** is `WGS84`.\n",
    "5. Due to download size constraints, we need to download this data in 4 chunks. Do the following:\n",
    "   - Split the full range of latitudes and longitudes in half, which yields the following 4 combinations of longitude-latitude ranges: $([-180, 0], [-90, 0]), ([-180, 0], [0, 90]), ([0, 180], [-90, 0])$, and $([0, 180], [0, 90])$.\n",
    "   - Under **Grid selection** again, one can select the range of longitudes and latitudes. Select one of the above combinations and press `start computation`.\n",
    "   - This will open up a new tab for calculations, which may take some time to complete. Once this is done, press **Download Grid**.\n",
    "   - Once the download is complete, go back to the previous page with **Model selection**, **Functional selection**, and more. Make sure the selections you made are intact, select another longitude-latitude combination, and repeat the process until there are no combinations left.\n",
    "6. Once the above steps are done, go back to Step 2 above; but instead of selecting `XGM2019e_2159` for **Model selection**, select `EGM96`. Go through the Steps 3 to 5 again with this new selection.\n",
    "7. Once the downloads for `XGM2019e_2159` and `EGM96` are complete, you should have 4 files for each model (8 in total, in `.gdf` format). Save the `XGM2019e_2159` files in `sset.DIR_GEOG_DATUMS_XGM2019e_WGS84` and `EGM96` files in `sset.DIR_GEOG_DATUMS_EGM96_WGS84`.\n",
    "\n",
    "### Global Mean Dynamic Ocean Topography (MDT) from AVISO+\n",
    "**Note**: While this dataset has a relatively open license, you will first need to obtain a MY AVISO+ account, which requires verification from the AVISO+ team and may take several days or weeks.\n",
    "1. Go to the following AVISO+ website for **MDT CNES-CLS18**: link [here](https://www.aviso.altimetry.fr/en/data/products/auxiliary-products/mdt/mdt-global-cnes-cls18.html).\n",
    "2. Once on the page, download the dataset through your MY AVISO+ account (click on `access via MY AVISO+` link and follow the instructions).\n",
    "3. After following the instructions, you will acquire the file `mdt_cnes_cls18_global.nc.gz`. Extract the file `mdt_cnes_cls18_global.nc` from the `.gz` file and save it as `sset.PATH_GEOG_MDT_RAW`.\n",
    "\n",
    "### CIA World Factbook (compiled by Coleman [2020])\n",
    "\n",
    "1. Travel to this [link](https://github.com/iancoleman/cia_world_factbook_api) (credit to Coleman [2020]), and scroll down to the `readme.md`.\n",
    "2. In the **Data** section of the `readme.md` file, there should be a link on \"Historical\"; click on this link to travel to a `mega.nz` website having `weekly_json.7z` file.\n",
    "3. After checking that the filename to download is `weekly_json.7z`, download the said file by clicking on the \"Download\" button.\n",
    "4. When download is successful, import `weekly_json.7z` to the preferred directory (`sset.DIR_YPK_RAW` in this implementation).\n",
    "\n",
    "### HydroSHEDS\n",
    "1. Go to https://hydrosheds.org/downloads\n",
    "2. Download the \"standard\" level-0 HydroBASINS files for each continent (use the Dropbox link if available--this appears as \"NOTE: you may also download data from here.\" as of 8/16/21. Download the shapefiles into the directory defined in `sset.DIR_HYDROBASINS_RAW`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f5274-f65c-41a3-8deb-7e62069f6138",
   "metadata": {},
   "source": [
    "### Other SLIIDERS input datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b048d8c-ef4e-4119-9de5-9ec341f0d5a5",
   "metadata": {},
   "source": [
    "There are three datasets that were manually constructed for use in `SLIIDERS`. They are available for download on Zenodo. Please download each file from the Zenodo deposit [here](https://doi.org/10.5281/zenodo.6450169) and copy to the paths designated for each dataset.\n",
    "\n",
    "#### 1. `ne_coastline_lines_CIAM_wexp_or_gtsm.shp`\n",
    "Path: `sset.PATH_CIAM_COASTLINES` (Download all files with the name `ne_coastline_lines_CIAM_wexp_or_gtsm` (but different extensions) to this directory.)  \n",
    "\n",
    "Using the global coastlines derived from the Natural Earth layers, we included individual land masses formed by these coastlines only if they have either i) a non-zero value of exposure based on our exposure grid for population and capital assets, OR ii) if they have an associated coastal segment point, as derived primarily from the CoDEC GTSM station points. Association of a given land mass to nearby CoDEC point(s) was determined through manual inspection of the subset of land masses (n=636) with zero exposure in order to assess whether an intersecting or nearby station point represented that land area, resulting in the inclusion of 171 small land masses for which no population or capital is present but for which a coast point is associated.\n",
    "\n",
    "#### 2. `gtsm_stations_eur_tothin.shp`\n",
    "Path: `sset.DIR_GTSM_STATIONS_TOTHIN` (Download all files with the name `gtsm_stations_eur_tothin` (but different extensions) to this directory.)  \n",
    "\n",
    "These 5,637 station points are a subset of the full CoDEC dataset (n=14,110) representing sites along European coastlines that are roughly five times more densely-spaced compared to the rest of the globe, as described in Muis et al. 2020. This subset of points are those that will be thinned by 5x to approximately match the density of CoDEC coast stations globally. Some manual inclusion criteria for this subset was applied in GIS due to the fact that simply seeking to select dense European stations based on the “station_name” field in the dataset, which contains the substring “eur” for all European locations, results in an over-selection of desired points (n=6,132), with many North African coastal points that are not densely-spaced containing this substring in their “station_name” as well. Therefore, European points were manually identified, with small islands, such as in the Mediterranean, included if their land mass contained 5 or more station points, which guarantees that they will be represented by at least one station point following the 5x thinning process. The resultant subset of points is used as a data input for the coastal segment construction in the preprocessing of the SLIIDERS dataset.\n",
    "\n",
    "#### 3. `us_manual_protected_areas.parquet`\n",
    "Path: `sset.PATH_US_MANUAL_PROTECTED_AREAS`  \n",
    "\n",
    "The regions defined in this dataset represent a few areas in the United States that may have low-lying elevations, but are not vulnerable to flooding due to constructed barriers or since they are completely separated from the coastline by topographical features with much higher elevations. Areas protected by Louisiana levees were downloaded from the National Levee Database (https://levees.sec.usace.army.mil/), and areas corresponding to low-lying areas in California, Missouri, and Michigan that are not vulnerable to coastal flooding were created using spatial buffers around a central point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0323ad0-afc1-43bf-9e5b-82e37e5455ce",
   "metadata": {},
   "source": [
    "### CoastalDEM v1.1\n",
    "1. Acquire the global 1 arc-second CoastalDEM dataset from Climate Central (https://go.climatecentral.org/coastaldem/).\n",
    "2. Save all 1-degree GeoTIFF files in `sset.DIR_COASTALDEM`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
