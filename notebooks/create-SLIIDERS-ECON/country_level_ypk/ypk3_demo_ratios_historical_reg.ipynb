{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68fee01c-c1cb-4120-8c8f-319624f439b1",
   "metadata": {},
   "source": [
    "## Code for creating \"demographic ratios,\" \"demographic variables,\" other variables needed for the \"historical regression\" (based on Higgins, 1998, International Economic Review), and executing the said regression\n",
    "\n",
    "This notebook was written to execute the following tasks:\n",
    "- Create \"demographic ratios,\" which are the shares of specific age-groups (0-4, 5-9, ..., 65-69, and 70+) for each country; these will be made in five-year moving averages, for the \"historical regression\" (based on Higgins, 1998, Int. Econ. Rev.)\n",
    "- Create \"demographic variables,\" which are created from the demographic ratios and are used the historical regression\n",
    "- Create other variables created from on GDPpc and its grwoth rate to be used in the historical regression\n",
    "- Conduct the historical regression and project missing values for the I-Y ratios\n",
    "\n",
    "## Setting\n",
    "\n",
    "### Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c2bff0-2778-4158-b2e1-129d1aabdd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432995b6-2134-40d4-8704-8f14f0cea373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sliiders import country_level_ypk as ypk_fn\n",
    "from sliiders import settings as sset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f59da9e-de72-4e2e-a0d7-83b16fe6dd1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating (five-year averages of) demographic ratios\n",
    "\n",
    "### Importing necessary datasets\n",
    "\n",
    "We note that the population values in the dataset we cleaned up is in millions of people whereas the UN data is in thousands of people. Therefore, we will divide the columns `PopMale`, `PopFemale`, and `PopTotal` by 1000 to keep all values in millions of people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5b745b-4771-4099-8fec-8aa559dcb0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall population stuff\n",
    "pop = pd.read_parquet(\n",
    "    sset.DIR_YPK_INT / \"gdp_gdppc_pop_capital_1950_2020_post_ypk3.parquet\"\n",
    ")\n",
    "\n",
    "# let us set aside the uninhabited areas\n",
    "pop = pop.loc[\n",
    "    ~pop.index.get_level_values(\"ccode\").isin(sset.UNINHABITED_ISOS), :\n",
    "].sort_index()\n",
    "ccodes = pop.index.get_level_values(\"ccode\").unique()\n",
    "\n",
    "# by-age population\n",
    "by_age = pd.read_parquet(sset.DIR_YPK_INT / \"un_population_by_age.parquet\")\n",
    "for i in [\"PopMale\", \"PopFemale\", \"PopTotal\"]:\n",
    "    by_age[i] = by_age[i] / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97afbfd6-7d25-4472-95b3-4540d5b883fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gathering the age groups\n",
    "\n",
    "#### For all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3852080c-ecc9-499f-80d9-46df97bd168b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## generating groups\n",
    "yrs = np.arange(0, 70, 5)\n",
    "groups = [\"-\".join([str(x), str(x + 4)]) for x in yrs]\n",
    "\n",
    "## easier mapping from group names to group numbering\n",
    "dic = dict(zip(groups, range(1, len(groups) + 1)))\n",
    "case_df = pd.DataFrame(\n",
    "    np.vstack([list(dic.keys()), list(dic.values())]).T, columns=[\"AgeGrp\", \"group_num\"]\n",
    ")\n",
    "\n",
    "## group numbering attach\n",
    "by_age_cleaning = by_age.reset_index().merge(case_df, on=\"AgeGrp\", how=\"left\")\n",
    "\n",
    "## if no group number (i.e., the highest age group), just create a new one\n",
    "by_age_cleaning.loc[pd.isnull(by_age_cleaning.group_num), \"group_num\"] = (\n",
    "    max(list(dic.values())) + 1\n",
    ")\n",
    "\n",
    "## gathering by the generated group numberings\n",
    "by_age_cleaning = by_age_cleaning.groupby([\"ccode\", \"Time\", \"group_num\"]).sum()\n",
    "by_age_cleaning.reset_index(inplace=True)\n",
    "\n",
    "## reorganizing, data type-setting\n",
    "by_age_cleaning = by_age_cleaning.astype({\"Time\": \"int64\", \"group_num\": \"int64\"})\n",
    "by_age_cleaning.rename(columns={\"Time\": \"year\"}, inplace=True)\n",
    "by_age_cleaning.set_index([\"ccode\", \"year\", \"group_num\"], inplace=True)\n",
    "by_age_cleaning.sort_index(inplace=True)\n",
    "\n",
    "## Only want 2020 and before\n",
    "by_age_cleaning = by_age_cleaning.loc[\n",
    "    by_age_cleaning.index.get_level_values(\"year\") <= 2020, [\"PopTotal\"]\n",
    "].copy()\n",
    "\n",
    "## again, cleaning and merging in the group names\n",
    "case_df = case_df.astype({\"group_num\": \"int64\"}).set_index([\"group_num\"])\n",
    "by_age_cleaning = by_age_cleaning.merge(\n",
    "    case_df, left_index=True, right_index=True, how=\"left\"\n",
    ")\n",
    "\n",
    "## if missing group name, this should be for over 70+\n",
    "by_age_cleaning.loc[pd.isnull(by_age_cleaning.AgeGrp), \"AgeGrp\"] = \"70+\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfeaadf-08e1-4792-9528-50c8c2735552",
   "metadata": {},
   "source": [
    "#### Taking care of the Channel Islands, and setting aside their information\n",
    "\n",
    "We find that the `grps_df` actually includes the information for the Channel Islands, which we can separate out to Guernsey and Jersey (`GGY` and `JEY`). In the said separation effort, what we will do is to use the average ratio of `GGY` population and `JEY` population between the years 2009-2019 as noted in the previous file (`ypk3_reorg_and_impute_ypk.ipynb`). The reason for using the years 2009-2019 is because we have actual data for `GGY` for those years in Guernsey Annual Electronic Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb9ac1c-b1d9-45f5-b216-0d7ac4564a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GGY and JEY ratios\n",
    "ggy_0919 = pop.loc[(\"GGY\", list(range(2009, 2020))), \"pop\"].values\n",
    "jey_0919 = pop.loc[(\"JEY\", list(range(2009, 2020))), \"pop\"].values\n",
    "ggy_ratio = (ggy_0919 / (ggy_0919 + jey_0919)).mean()\n",
    "jey_ratio = (jey_0919 / (ggy_0919 + jey_0919)).mean()\n",
    "\n",
    "## separating out JEY and GGY\n",
    "channel = by_age_cleaning.loc[(\"GGY+JEY\", slice(None), slice(None)), :].copy()\n",
    "ggy, jey = channel.reset_index(), channel.reset_index()\n",
    "ggy[\"PopTotal\"] = ggy[\"PopTotal\"].values * ggy_ratio\n",
    "jey[\"PopTotal\"] = jey[\"PopTotal\"].values * jey_ratio\n",
    "ggy[\"ccode\"], jey[\"ccode\"] = \"GGY\", \"JEY\"\n",
    "ggy.set_index([\"ccode\", \"year\", \"group_num\"], inplace=True)\n",
    "jey.set_index([\"ccode\", \"year\", \"group_num\"], inplace=True)\n",
    "\n",
    "## merging stuff together\n",
    "by_age_cleaning = pd.concat(\n",
    "    [\n",
    "        ggy,\n",
    "        jey,\n",
    "        by_age_cleaning.loc[\n",
    "            by_age_cleaning.index.get_level_values(\"ccode\") != \"GGY+JEY\", :\n",
    "        ],\n",
    "    ],\n",
    "    axis=0,\n",
    ").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b301c-2c4c-4d94-a0e8-68becace7c4a",
   "metadata": {},
   "source": [
    "### Creating demographic ratios of age-group population 5-year-averages, and extrapolating for missing countries\n",
    "\n",
    "#### 5-year-averages of age-group population\n",
    "\n",
    "To be exact, this would be the 5 previous years' averages. If there are less than 5 previous years available (for 1950-1954), we use whatever previous years we have, with the exception of year 1950 where the 1950 values are copied due to lack of previous-years data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864ce4b-d0c0-4e78-b34b-9b992cf537ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_age_cleaning[\"avg_5_yrs\"] = np.nan\n",
    "\n",
    "for i in tqdm(range(1950, 2021)):\n",
    "    if i in [1950, 1951]:\n",
    "        by_age_cleaning.loc[(slice(None), i), \"avg_5_yrs\"] = by_age_cleaning.loc[\n",
    "            (slice(None), 1950), \"PopTotal\"\n",
    "        ].values\n",
    "        continue\n",
    "    elif i in [1952, 1953, 1954]:\n",
    "        prev_yrs = list(range(1950, i))\n",
    "    else:\n",
    "        prev_yrs = list(range(i - 5, i))\n",
    "\n",
    "    for j, yr in enumerate(prev_yrs):\n",
    "        name = \"pop_{}\".format(yr)\n",
    "        yr_df = by_age_cleaning.loc[(slice(None), yr, slice(None)), [\"PopTotal\"]]\n",
    "        yr_df.reset_index(inplace=True)\n",
    "        yr_df.drop([\"year\"], inplace=True, axis=1)\n",
    "        yr_df.rename(columns={\"PopTotal\": name}, inplace=True)\n",
    "        yr_df.set_index([\"ccode\", \"group_num\"], inplace=True)\n",
    "\n",
    "        if j == 0:\n",
    "            prev_df = yr_df.copy()\n",
    "        else:\n",
    "            prev_df = prev_df.merge(\n",
    "                yr_df, left_index=True, right_index=True, how=\"left\"\n",
    "            )\n",
    "\n",
    "    prev_df[\"prev_mean\"] = prev_df[[\"pop_{}\".format(x) for x in prev_yrs]].mean(axis=1)\n",
    "    prev_df.reset_index(inplace=True)\n",
    "    prev_df[\"year\"] = i\n",
    "    prev_df.set_index([\"ccode\", \"year\", \"group_num\"], inplace=True)\n",
    "    by_age_cleaning = by_age_cleaning.merge(\n",
    "        prev_df[[\"prev_mean\"]], left_index=True, right_index=True, how=\"left\"\n",
    "    )\n",
    "    by_age_cleaning.loc[(slice(None), i), \"avg_5_yrs\"] = by_age_cleaning.loc[\n",
    "        (slice(None), i), \"prev_mean\"\n",
    "    ].values\n",
    "    by_age_cleaning.drop([\"prev_mean\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1859a37-ee90-4950-a63b-97b82c79e6eb",
   "metadata": {},
   "source": [
    "#### Creating the demographic ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b555b-99b3-461a-8be4-e1cc93ae0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = by_age_cleaning.reset_index().groupby([\"ccode\", \"year\"]).sum()[[\"avg_5_yrs\"]]\n",
    "total.rename(columns={\"avg_5_yrs\": \"total\"}, inplace=True)\n",
    "by_age_cleaning = by_age_cleaning.merge(\n",
    "    total, left_index=True, right_index=True, how=\"left\"\n",
    ")\n",
    "by_age_cleaning[\"demo_ratio\"] = by_age_cleaning[\"avg_5_yrs\"] / by_age_cleaning[\"total\"]\n",
    "\n",
    "## setting aside the countries that we will actually use\n",
    "by_age_cleaning = by_age_cleaning.loc[\n",
    "    by_age_cleaning.index.get_level_values(\"ccode\").isin(ccodes), :\n",
    "].sort_index()\n",
    "\n",
    "by_age_cleaning.drop([\"total\"], inplace=True, axis=1)\n",
    "by_age_cleaning[\"demo_ratio_source\"] = \"UN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eb1d2d-b4c9-41f5-8af3-7253ba1c8d97",
   "metadata": {},
   "source": [
    "#### Finding the \"similar\" countries (in terms of population growth trajectory) creating demographic ratios by way of weighted averaging of similar countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad208aef-6584-4064-b6cb-2f11022697d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating growth rates of population\n",
    "pop_hor = ypk_fn.organize_ver_to_hor(\n",
    "    pop[[\"pop\"]], \"pop\", \"year\", \"ccode\", total_yrs=range(1950, 2021)\n",
    ")\n",
    "for i in range(1951, 2021):\n",
    "    v_, v_prev = \"v_{}\".format(i), \"v_{}\".format(i - 1)\n",
    "    newvar = \"r_{}\".format(i)\n",
    "    pop_hor[newvar] = pop_hor[v_] / pop_hor[v_prev] - 1\n",
    "\n",
    "## finding which countries we should extrapolate for, and extrapolate from\n",
    "msng_ccodes = np.setdiff1d(\n",
    "    ccodes, by_age_cleaning.index.get_level_values(\"ccode\").unique()\n",
    ")\n",
    "valid_ccodes = np.intersect1d(\n",
    "    ccodes, by_age_cleaning.index.get_level_values(\"ccode\").unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fecae9-adfe-436d-9579-6e181a0dccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similars_extrap_demog_ratio(\n",
    "    ctry, sim_df, demoratio_df, valid_ccodes, header=\"r_\", n_det=5\n",
    "):\n",
    "    \"\"\"Find `n_det` most similar countries (in terms of population trajectories)\n",
    "    for a certain country, among those that are listed in valid_ccodes. Then,\n",
    "    take a weighted average of those countries' to extrapolate demographic ratio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ctry : str\n",
    "        name of the country to find \"similar\"-trend countries for\n",
    "    sim_df : pandas DataFrame\n",
    "        wide-panel-format data to calculate trend-similarities for the `ctry` and other\n",
    "        countries. Should have yearly data that has column names starting with the\n",
    "        `header`\n",
    "    demoratio_df : pandas DataFrame\n",
    "        DataFrame containing information for the demographic ratio; should have the\n",
    "        column `demo_ratio` contained\n",
    "    valid_ccodes : array-like of str\n",
    "        DataFrame containing country codes which are \"valid\" ones to create extrapolated\n",
    "        demographic ratios from.\n",
    "    header : str\n",
    "        header of the columns in `sim_df` which are yearly variables to detect\n",
    "        similarities (in growth rate) from\n",
    "    n_det : int\n",
    "        number of country codes in `valid_ccodes` to created extrapolated demographic\n",
    "        ratios from; top `n_det` countries in terms of similaries are selected\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    extrap_df : pandas DataFrame\n",
    "        contains information about the extrapolated demographic ratios, specific for the\n",
    "        country code defined by `ctry`; has the variables `demo_ratio` for the\n",
    "        extrapolated demographic ratio, and `demo_ratio_source` for the countries whose\n",
    "        information was utilized to create the `demo_ratio` extrapolations. Has indices\n",
    "        `ccode`, `year`, and `group_num` for countrycode, year, and group numbering.\n",
    "\n",
    "    \"\"\"\n",
    "    goodcols = [x for x in sim_df.columns if header in x]\n",
    "    df_sse = (\n",
    "        sim_df.loc[valid_ccodes, goodcols].sub(sim_df.loc[ctry, goodcols].values).copy()\n",
    "    )\n",
    "    df_sse[\"sse\"] = (df_sse[goodcols].values ** 2).sum(axis=1)\n",
    "    df_sse[\"sse_rank\"] = df_sse[\"sse\"].rank()\n",
    "    df_sse.sort_values([\"sse_rank\"], inplace=True)\n",
    "    df_sse = df_sse.loc[df_sse.sse_rank <= n_det, [\"sse\", \"sse_rank\"]].copy()\n",
    "\n",
    "    extrap_df = demoratio_df.loc[\n",
    "        (df_sse.index.values, slice(None), slice(None)), [\"demo_ratio\"]\n",
    "    ].merge(df_sse[[\"sse\"]], left_index=True, right_index=True, how=\"left\")\n",
    "    denom = np.sum(1 / df_sse.sse)\n",
    "    extrap_df[\"numer\"] = extrap_df[\"demo_ratio\"] / extrap_df[\"sse\"]\n",
    "    extrap_df = extrap_df.reset_index().groupby([\"year\", \"group_num\"]).sum()[[\"numer\"]]\n",
    "    extrap_df[\"numer\"] = extrap_df[\"numer\"] / denom\n",
    "\n",
    "    extrap_df = extrap_df.reset_index().rename(columns={\"numer\": \"demo_ratio\"})\n",
    "    extrap_df[\"ccode\"] = ctry\n",
    "    extrap_df.set_index([\"ccode\", \"year\", \"group_num\"], inplace=True)\n",
    "    extrap_df[\"demo_ratio_source\"] = \",\".join(df_sse.index.values)\n",
    "\n",
    "    return extrap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8575a3-a863-4ff3-ad72-0f0b593fee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "msng_extrap_dfs = []\n",
    "for i in tqdm(msng_ccodes):\n",
    "    msng_extrap_dfs.append(\n",
    "        find_similars_extrap_demog_ratio(i, pop_hor, by_age_cleaning, valid_ccodes)\n",
    "    )\n",
    "msng_extrap_dfs = pd.concat(msng_extrap_dfs, axis=0)\n",
    "\n",
    "## creating a finalized version of the demographic ratio dataset\n",
    "demo_ratio_df = pd.concat(\n",
    "    [by_age_cleaning[[\"demo_ratio\", \"demo_ratio_source\"]], msng_extrap_dfs], axis=0\n",
    ").sort_index()\n",
    "\n",
    "## attaching the Age Group indicators\n",
    "demo_ratio_df = demo_ratio_df.merge(\n",
    "    case_df, how=\"left\", right_index=True, left_index=True\n",
    ")\n",
    "demo_ratio_df.loc[pd.isnull(demo_ratio_df.AgeGrp), \"AgeGrp\"] = \"70+\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfebd10-bcae-4878-87a5-ea73d8dea1a2",
   "metadata": {},
   "source": [
    "### Exporting the demographic ratios results\n",
    "\n",
    "Note that the uninhabited areas are, again, left out from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fdf070-0b31-401b-82a7-7a9472a9aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_ratio_df.to_parquet(sset.DIR_YPK_INT / \"demo_ratio_1950_2020.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fee9545-7ecd-4f4e-bc8c-9688dffefa9b",
   "metadata": {},
   "source": [
    "## Creating the \"demographic variables\"\n",
    "\n",
    "Demographic variables are a succinct way of representing different age group (demographic) ratios into just a few variables by assuming a functional (polynomial) form for how they enter the regression. If we assume a $l$th order polynomial form, there will be $k=1, 2, \\cdots, l$-order variables (so $l$ demographic variables to represent 15 demographic groups we have).\n",
    "\n",
    "For the $k$th order, we have\n",
    "\n",
    "$D_k = \\sum_{j=1}^J j^k p_j - \\frac{1}{J}\\sum_{j=1}^J j^k$\n",
    "\n",
    "where $J=15$ in our case (for the number of demographic groups considered) and $p_j$ is the demographic ratio of the $j$th group. Derivation of this form (and why we choose $l=3$ in this instance) is further explained in [Higgins (1995, International Economic Review, pp. 366-367)](https://www.jstor.org/stable/2527297)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72d132b-c139-4274-8547-d59b89804a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = pd.read_parquet(sset.DIR_YPK_INT / \"demo_ratio_1950_2020.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ffc47e-ea37-4240-abb8-6fa85158a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_k_generator(df, k=1, v_name=\"demo_ratio\"):\n",
    "    \"\"\"Function to generate the k-order demographic variable for each country.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        DataFrame containing column to generate the k-order demographic variable. Should\n",
    "        have indices `ccode`, `year`, and `group_num` to indicate country-code, year,\n",
    "        and group numbering for the country-year ratio variable (by groups)\n",
    "    k : int\n",
    "        order of the demographic variable to create\n",
    "    v_name : str\n",
    "        column name of the ratio variable, contained in the DataFrame `df`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    demovar_df : pandas DataFrame\n",
    "        DataFrame with the same `ccode`, `year`, and `group_num` index information but\n",
    "        containing a single variable, which is the calculated `k`-th order demographic\n",
    "        variable with the name `D{k}`.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    astmsg = \"Assign the indices ccode, year, group_num correctly\"\n",
    "    assert [\"ccode\", \"year\", \"group_num\"] == demo.index.names, astmsg\n",
    "\n",
    "    groups = np.sort(df.index.get_level_values(\"group_num\").unique())\n",
    "    N_groups = len(groups)\n",
    "    groups_pwr_k = groups**k\n",
    "    to_subtract = np.mean(groups_pwr_k)\n",
    "\n",
    "    group_df = pd.DataFrame(data={\"grp_k\": groups_pwr_k, \"group_num\": groups})\n",
    "    group_df.set_index([\"group_num\"], inplace=True)\n",
    "\n",
    "    demovar_df = df.merge(group_df, left_index=True, right_index=True, how=\"left\")\n",
    "    demovar_df[\"grp_k_prod_ratio\"] = demovar_df[v_name] * demovar_df[\"grp_k\"]\n",
    "    demovar_df = (\n",
    "        demovar_df.reset_index().groupby([\"ccode\", \"year\"]).sum()[[\"grp_k_prod_ratio\"]]\n",
    "    )\n",
    "    demovar_df[\"D{}\".format(k)] = demovar_df[\"grp_k_prod_ratio\"] - to_subtract\n",
    "\n",
    "    return demovar_df[[\"D{}\".format(k)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c6ac4-ca0a-49c2-a7b5-1046ae17338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## demographic variables (orders 1, 2, 3) and source\n",
    "demovar_df = D_k_generator(demo).merge(\n",
    "    D_k_generator(demo, k=2), how=\"left\", right_index=True, left_index=True\n",
    ")\n",
    "demovar_df = demovar_df.merge(\n",
    "    D_k_generator(demo, k=3), how=\"left\", right_index=True, left_index=True\n",
    ")\n",
    "demo_source = demo.loc[(slice(None), 1950, 1), [\"demo_ratio_source\"]].reset_index()\n",
    "demo_source.drop([\"year\", \"group_num\"], inplace=True, axis=1)\n",
    "demo_source.set_index([\"ccode\"], inplace=True)\n",
    "demovar_df = demovar_df.merge(\n",
    "    demo_source.rename(columns={\"demo_ratio_source\": \"demo_var_source\"}),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f953a55e-13de-4c11-a504-f7b4fcc92f02",
   "metadata": {},
   "source": [
    "## Creating other variables to be used in the \"historical regression\" for I-Y ratios (based on Higgins, 1995, Int. Econ. Rev.)\n",
    "\n",
    "### Creating \"yhat\"\n",
    "\n",
    "By \"yhat\" or $\\hat{y}_t$, we mean the following:\n",
    "\n",
    "$$ \\hat{y}_t = \\frac{1}{5}\\sum_{i=1}^{5} y_{t-i} \\quad t \\geq 1955 $$\n",
    "\n",
    "where $y_{t}$ is year $t$'s value of GDP per capita (in ones of constant 2017 PPP USD). So essentially, it would be the 5-year average of GDPpc of a certain country for the 5 previous year to the year $t$. However, notice that for $t \\leq 1954$, since we only have data up to 1950, we won't be able to take the 5-year average. Therefore, instead, we will use the following $n \\in \\{1, 2, 3, 4\\}$-year averages:\n",
    "\n",
    "$$ \\hat{y}_t = \\begin{cases}\n",
    "   y_{1950} & \\text{ if }t = 1950, 1951 \\\\\n",
    "   \\frac{1}{n} \\sum_{j=1950}^{1949+n} y_{j} & \\text{ if }t \\in \\{1952, 1953, 1954\\} \\text{ (and $n = t - 1950 $)}\n",
    "\\end{cases} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7493c1-d408-44e2-918a-218da2eea5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdppc = pd.read_parquet(\n",
    "    sset.DIR_YPK_INT / \"gdp_gdppc_pop_capital_1950_2020_post_ypk3.parquet\"\n",
    ")\n",
    "yvar = \"rgdpna_pc_17\"\n",
    "gdppc[\"yhat\"] = np.nan\n",
    "\n",
    "for i in tqdm(range(1950, 2021)):\n",
    "    if i in [1950, 1951]:\n",
    "        gdppc.loc[(slice(None), i), \"yhat\"] = gdppc.loc[\n",
    "            (slice(None), 1950), yvar\n",
    "        ].values\n",
    "        continue\n",
    "    elif i in [1952, 1953, 1954]:\n",
    "        prev_range = range(1950, i)\n",
    "    else:\n",
    "        prev_range = range(i - 5, i)\n",
    "\n",
    "    for yr in prev_range:\n",
    "        yr_df = gdppc.loc[(slice(None), yr), [yvar]].reset_index()\n",
    "        yr_df = yr_df.drop([\"year\"], axis=1).rename(columns={yvar: \"y_{}\".format(yr)})\n",
    "        yr_df.set_index([\"ccode\"], inplace=True)\n",
    "        if yr == prev_range[0]:\n",
    "            prev_df = yr_df.copy()\n",
    "        else:\n",
    "            prev_df = prev_df.merge(\n",
    "                yr_df, left_index=True, right_index=True, how=\"left\"\n",
    "            )\n",
    "    prev_df[\"yhat_i\"] = prev_df[[\"y_{}\".format(x) for x in prev_range]].mean(axis=1)\n",
    "    gdppc = gdppc.merge(\n",
    "        prev_df[[\"yhat_i\"]], left_index=True, right_index=True, how=\"left\"\n",
    "    )\n",
    "    gdppc.loc[(slice(None), i), \"yhat\"] = gdppc.loc[(slice(None), i), \"yhat_i\"].values\n",
    "    gdppc.drop([\"yhat_i\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdeb42b-f966-4685-8c21-1425256c3b42",
   "metadata": {},
   "source": [
    "### Creating \"ghat\"\n",
    "\n",
    "By \"ghat\" or $\\hat{g}_t$, we mean the following:\n",
    "\n",
    "$$ \\hat{g}_t = \\begin{cases} \\frac{\\hat{y}_{t}}{\\hat{y}_{t-1}} - 1  & \\text{ if $\\hat{y}_{t-1} > 0$} \n",
    "\\\\ 1 & \\text{ if $\\hat{y}_{t-1} = 0$ and $\\hat{y}_{t} > 0$}\n",
    "\\\\ 0 & \\text{ otherwise}\\end{cases} $$\n",
    "\n",
    "In other words, it would be the previous year's growth rate (of GDPpc) with respect to the 5-year average of the previous year's 5 previous years. Since we do not have information for the year 1949, I will set $\\hat{g}_{1950} = \\hat{g}_{1951}$. Note that \"ghat\" will be actually used as a regressor in the historical regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc81ee2-7590-4e10-b46e-e22b103c326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_yhat = gdppc[[\"yhat\"]].reset_index().rename(columns={\"yhat\": \"prev_yhat\"})\n",
    "prev_yhat[\"year\"] = prev_yhat[\"year\"] + 1\n",
    "prev_yhat.set_index([\"ccode\", \"year\"], inplace=True)\n",
    "gdppc = gdppc.merge(prev_yhat, left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "gdppc[\"ghat\"] = gdppc[\"yhat\"] / gdppc[\"prev_yhat\"] - 1\n",
    "gdppc.loc[(slice(None), 1950), \"ghat\"] = gdppc.loc[(slice(None), 1951), \"ghat\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97df27d-31cf-416d-8b53-aeaae0f9ada5",
   "metadata": {},
   "source": [
    "### Creating \"yhat rate\"\n",
    "\n",
    "By \"yhat rate\" or $\\hat{yr}_t$, I will mean the following:\n",
    "\n",
    "$$ \\hat{yr}_{i,t} = \\frac{\\hat{y}_{i,t}}{\\hat{y}_{US, t}}$$\n",
    "\n",
    "where $i$ is a country. Note that the \"yhat rate\" will be used as a regressor in the historical regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81eb2ab-c411-4bee-b257-f32674ad1fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_usa = gdppc.loc[(\"USA\", slice(None)), [\"yhat\"]].reset_index()\n",
    "yhat_usa = (\n",
    "    yhat_usa.drop([\"ccode\"], axis=1)\n",
    "    .set_index([\"year\"])\n",
    "    .rename(columns={\"yhat\": \"yhat_us\"})\n",
    ")\n",
    "\n",
    "gdppc = gdppc.merge(yhat_usa, left_index=True, right_index=True, how=\"left\")\n",
    "gdppc[\"yhat_rate\"] = gdppc[\"yhat\"] / gdppc[\"yhat_us\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eb34fb-f955-4ca3-b88c-f799d33907aa",
   "metadata": {},
   "source": [
    "### Organizing the dataframe for the historical regression and exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc72259-451b-4ce9-9db7-06e6e2436705",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_reg_df = gdppc[[\"iy_ratio\", \"yhat_rate\", \"ghat\", \"gdp_source\"]].copy()\n",
    "hist_reg_df[\"yhr_sq\"] = hist_reg_df[\"yhat_rate\"] ** 2\n",
    "hist_reg_df[\"ghat_sq\"] = hist_reg_df[\"ghat\"] ** 2\n",
    "\n",
    "hist_reg_df = hist_reg_df.merge(\n",
    "    demovar_df, left_index=True, right_index=True, how=\"left\"\n",
    ")\n",
    "for i in [\"D1\", \"D2\", \"D3\"]:\n",
    "    hist_reg_df[\"{}_x_ghat\".format(i)] = hist_reg_df[i] * hist_reg_df[\"ghat\"]\n",
    "\n",
    "hist_reg_df.to_parquet(sset.DIR_YPK_INT / \"hist_reg_prep.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1dbf13-f2cc-4ba5-8dcd-067de4d1033d",
   "metadata": {},
   "source": [
    "## Historical regression\n",
    "\n",
    "### Conducting the fit\n",
    "\n",
    "To summarize, the regression **with** demographic variables can be written as:\n",
    "\n",
    "$$ \\left(\\frac{I}{Y}\\right)_{c, t} = \\alpha_c + \\beta_1 \\hat{yhr}_{c, t} + \\beta_2 (\\hat{yhr}_{c, t})^2 + \\beta_3 \\hat{g}_{c, t} + \\beta_4 (\\hat{g}_{c, t})^2 + \\sum_{k=1}^3 \\left(\\gamma_k D_{k, c, t} + \\zeta_k [D_{k, c, t} \\times \\hat{g}_{c, t}]\\right) + \\varepsilon_{c, t}$$\n",
    "\n",
    "where the demographic terms are the ones involving $D_{k,c, t}$ and should be removed in the version where demographic variables are *not* used.\n",
    "\n",
    "Brief conclusion with AIC, BIC, and adjusted $R^2$ comparison shows that it is better to include the demographic variables in terms of the model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e81d9-dc61-46cb-8c63-d30469bcc1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DF to fit for the historical regression\n",
    "hist_fit_df = hist_reg_df.loc[\n",
    "    ~pd.isnull(hist_reg_df[hist_reg_df.columns]).any(axis=1), :\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fc9b82-a8f8-4cd3-ad4f-c0ab1c8bceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_with_selected(\n",
    "    df_orig, lhs, fe=True, exclude_rhs=[\"gdp_source\", \"demo_var_source\"]\n",
    "):\n",
    "    \"\"\"Running a OLS model with clustered standard errors (clustered at the country\n",
    "    level) and returning the fitting result.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_orig : pandas DataFrame\n",
    "        containing information about the `lhs` variable as well as other variables to be\n",
    "        used as regressors in the OLS model. Should have `ccode` as one of the index\n",
    "        columns.\n",
    "    lhs : str\n",
    "        information in `df_orig` to be used as the regressand\n",
    "    fe : boolean\n",
    "        if True, creates and applies country-level fixed effects to the OLS; if False,\n",
    "        does not create the said fixed effects\n",
    "    exclude_rhs : array-like of str\n",
    "        contains column names in `df_orig` that should not be used as regressors\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ols_results : statsmodels.regression.linear_model.RegressionResults\n",
    "        containing OLS results\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    c = np.sort(df_orig.index.get_level_values(\"ccode\").unique())\n",
    "    rhs = [x for x in df_orig.columns if (x not in list(exclude_rhs) + [lhs])]\n",
    "    df = df_orig.reset_index()\n",
    "\n",
    "    if fe:\n",
    "        df = pd.concat([df, pd.get_dummies(df[\"ccode\"])], axis=1)\n",
    "        ols_setup = sm.OLS(df[lhs], sm.add_constant(df[rhs + list(c[1:])]))\n",
    "        ols_results = ols_setup.fit(cov_kwds={\"groups\": df.ccode}, cov_type=\"cluster\")\n",
    "    else:\n",
    "        ols_setup = sm.OLS(df[lhs], sm.add_constant(df[rhs]))\n",
    "        ols_results = ols_setup.fit(cov_kwds={\"groups\": df.ccode}, cov_type=\"cluster\")\n",
    "\n",
    "    return ols_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee6add-c3ff-4e93-ae12-a743cc979445",
   "metadata": {},
   "source": [
    "Based on better adjusted $R^2$, AIC, and BIC values, we will stick with the regression with demographic variables included (as opposed to that without)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef79fec-182e-4963-94f9-116d24d0853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "histreg_demog = ols_with_selected(hist_fit_df, \"iy_ratio\")\n",
    "demog_vars = [\n",
    "    x for x in hist_fit_df.columns if (\"D1\" in x) or (\"D2\" in x) or (\"D3\" in x)\n",
    "]\n",
    "demog_vars += [\"gdp_source\", \"demo_var_source\"]\n",
    "histreg_nodemog = ols_with_selected(hist_fit_df, \"iy_ratio\", exclude_rhs=demog_vars)\n",
    "\n",
    "d_ar2 = round(histreg_demog.rsquared_adj, 4)\n",
    "n_ar2 = round(histreg_nodemog.rsquared_adj, 4)\n",
    "print(\"With demog. adj R2: {}, no demog. adj R2: {}\".format(d_ar2, n_ar2))\n",
    "print(\"With demog. has better AIC:\", histreg_nodemog.aic > histreg_demog.aic)\n",
    "print(\"With demog. has better BIC:\", histreg_nodemog.bic > histreg_demog.bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d1487-2e36-4a3c-a916-cad2ff7641e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cols = [\"ghat\", \"ghat_sq\", \"yhat_rate\", \"yhr_sq\", \"D1\", \"D2\", \"D3\"]\n",
    "res_cols += [\"D1_x_ghat\", \"D2_x_ghat\", \"D3_x_ghat\"]\n",
    "res_df = pd.DataFrame(histreg_demog.params, columns=[\"d_beta\"]).loc[res_cols, :]\n",
    "d_bse, d_p = histreg_demog.bse, histreg_demog.pvalues\n",
    "d_bse.name, d_p.name = \"d_se\", \"d_p\"\n",
    "\n",
    "nd_param = histreg_nodemog.params\n",
    "nd_param.name = \"nd_beta\"\n",
    "nd_bse, nd_p = histreg_nodemog.bse, histreg_nodemog.pvalues\n",
    "nd_bse.name, nd_p.name = \"nd_se\", \"nd_p\"\n",
    "\n",
    "for l in [d_bse, d_p, nd_param, nd_bse, nd_p]:\n",
    "    res_df = res_df.join(l, how=\"left\")\n",
    "\n",
    "print(res_df)\n",
    "\n",
    "ctries = [x for x in d_p.index.values if (len(x) == 3) or (x not in res_cols)]\n",
    "d_fes, nd_fes = d_p.loc[ctries].values, nd_p.loc[ctries].values\n",
    "print()\n",
    "print(\n",
    "    \"FEs significant (%), D:\",\n",
    "    round(len(d_fes[d_fes < 0.05]) / len(ctries), 4) * 100,\n",
    "    \"; ND:\",\n",
    "    round(len(nd_fes[nd_fes < 0.05]) / len(ctries), 4) * 100,\n",
    ")\n",
    "print()\n",
    "print(histreg_nodemog.aic, histreg_demog.aic)\n",
    "print(histreg_nodemog.bic, histreg_demog.bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db9662-f4f2-45aa-bb87-e46c86af024e",
   "metadata": {},
   "source": [
    "We will also estimate the model without fixed effects due to some countries having no I-Y information whatsoever (but we still need to estimate their information). Based on better adjusted $R^2$, AIC, and BIC values, we will again stick with the regression with demographic variables included. Unfortunately, the $R^2$ is not too high without the fixed effects involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f811708b-4614-4e11-b2d7-72f832729cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "histreg_demog_nofe = ols_with_selected(hist_fit_df, \"iy_ratio\", False)\n",
    "histreg_nodemog_nofe = ols_with_selected(hist_fit_df, \"iy_ratio\", False, demog_vars)\n",
    "\n",
    "d_ar2 = round(histreg_demog_nofe.rsquared_adj, 4)\n",
    "n_ar2 = round(histreg_nodemog_nofe.rsquared_adj, 4)\n",
    "print(\"With demog. adj R2: {}, no demog. adj R2: {}\".format(d_ar2, n_ar2))\n",
    "print(\"With demog. has better AIC:\", histreg_nodemog_nofe.aic > histreg_demog_nofe.aic)\n",
    "print(\"With demog. has better BIC:\", histreg_nodemog_nofe.bic > histreg_demog_nofe.bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aedb551-c95d-443f-bf8d-af5570cf5409",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df2 = pd.DataFrame(histreg_demog_nofe.params, columns=[\"d_beta\"]).loc[res_cols, :]\n",
    "d_bse, d_p = histreg_demog_nofe.bse, histreg_demog_nofe.pvalues\n",
    "d_bse.name, d_p.name = \"d_se\", \"d_p\"\n",
    "\n",
    "nd_param = histreg_nodemog_nofe.params\n",
    "nd_param.name = \"nd_beta\"\n",
    "nd_bse, nd_p = histreg_nodemog_nofe.bse, histreg_nodemog_nofe.pvalues\n",
    "nd_bse.name, nd_p.name = \"nd_se\", \"nd_p\"\n",
    "\n",
    "for l in [d_bse, d_p, nd_param, nd_bse, nd_p]:\n",
    "    res_df2 = res_df2.join(l, how=\"left\")\n",
    "\n",
    "print(res_df2)\n",
    "print()\n",
    "print(histreg_nodemog_nofe.aic, histreg_demog_nofe.aic)\n",
    "print(histreg_nodemog_nofe.bic, histreg_demog_nofe.bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adec3a9-3c54-462b-ae50-689fd17c35d8",
   "metadata": {},
   "source": [
    "### Projections for missing I-Y ratios\n",
    "\n",
    "#### Projections for those with partial I-Y information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dadb3bd-daef-4173-8d33-5b02663f37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_fe = np.sort(hist_fit_df.index.get_level_values(\"ccode\").unique())\n",
    "yes_fe_fit = hist_reg_df.loc[(yes_fe, slice(None)), :].reset_index()\n",
    "yes_fe_fit = pd.concat([yes_fe_fit, pd.get_dummies(yes_fe_fit.ccode)], axis=1)\n",
    "yes_fe_fit[\"iy_ratio_pred\"] = histreg_demog.predict(\n",
    "    sm.add_constant(yes_fe_fit)[histreg_demog.params.index.values]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5209502c-5ea1-4675-9277-e3f743f8b7cf",
   "metadata": {},
   "source": [
    "#### Projections for those with no I-Y information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326334a-9668-43cd-a22a-8e0b444fbdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_fe_fit = hist_reg_df.loc[\n",
    "    ~hist_reg_df.index.get_level_values(\"ccode\").isin(yes_fe), :\n",
    "].reset_index()\n",
    "no_fe_fit[\"iy_ratio_pred\"] = histreg_demog_nofe.predict(\n",
    "    sm.add_constant(no_fe_fit)[histreg_demog_nofe.params.index.values]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1465492-f5a8-48f5-82af-bf65bcfb0aba",
   "metadata": {},
   "source": [
    "#### Merging the two cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17dbb06-7024-49a5-920b-295a7f4b02cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"ccode\", \"year\", \"iy_ratio\", \"iy_ratio_pred\"]\n",
    "fitted_iy = pd.concat([yes_fe_fit[cols], no_fe_fit[cols]], axis=0).set_index(cols[0:2])\n",
    "fitted_iy[\"iy_ratio_fit\"] = fitted_iy[\"iy_ratio\"]\n",
    "fitted_iy.loc[pd.isnull(fitted_iy.iy_ratio), \"iy_ratio_fit\"] = fitted_iy.loc[\n",
    "    pd.isnull(fitted_iy.iy_ratio), \"iy_ratio_pred\"\n",
    "].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ff4c5-5d0b-4775-b287-0a7df19db6be",
   "metadata": {},
   "source": [
    "#### Some diagnostics (graphing, checking whether any values are above 1 or below 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd71a8-080e-4eef-9184-6962d0d0aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_trajectory(ctry, df=fitted_iy):\n",
    "    \"\"\"Creates a simple graph drawing the actual investment-to-GDP ratio in the data\n",
    "    and the fitted (or predicted) investment-to-GDP ratio using the OLS model, for a\n",
    "    single country specified by `ctry`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ctry : str\n",
    "        name of the country\n",
    "    df : pandas DataFrame\n",
    "        DataFrame containing the variables `iy_ratio` (for the actual investment-to-GDP\n",
    "        ratios) and `iy_ratio_pred` (for the predicted investment-to-GDP ratios)\n",
    "        with indices `ccode` (for country-codes) and `year`, in that order\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None, but produces the aforementioned graphs for `ctry`\n",
    "\n",
    "    \"\"\"\n",
    "    years = np.sort(df.index.get_level_values(\"year\").unique())\n",
    "    actual = df.loc[(ctry, slice(None)), \"iy_ratio\"].values\n",
    "    fitted = df.loc[(ctry, slice(None)), \"iy_ratio_pred\"].values\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    if not pd.isnull(actual).all():\n",
    "        plt.plot(years, actual, label=\"Actual I-Y\", color=\"black\")\n",
    "    plt.plot(years, fitted, label=\"Fitted I-Y\", color=\"orange\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Investment-to-GDP ratio\")\n",
    "    plt.title(\"Investment-to-GDP ratio for {}\".format(ctry))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b931dbf-7758-4b10-91b1-2ee7aaa36435",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_trajectory(\"ARG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf582af-629b-465e-a63d-260a7d1e4522",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_trajectory(\"USA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb40f26-58bd-4d46-9f9f-138e7f161e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## not-so-good case with Libya\n",
    "graph_trajectory(\"LBY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af47ff-8d0f-4f9b-938b-effac035dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## not-so-good case with China\n",
    "graph_trajectory(\"CHN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2b0105-ec81-4ca7-82f1-a43a5ba81c78",
   "metadata": {},
   "source": [
    "We can also see that there are some cases where the I-Y ratios are lesser than 0 or larger than 1; however, these are all from the original sources (mostly from PWT10.0's `csh_i` variable, except for `LBY` where the values are from IMF). Therefore, we will keep things as is and accept these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23feb54-3a99-4fb5-8c67-864a4e3c0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_iy.loc[(fitted_iy.iy_ratio_fit < 0) | (fitted_iy.iy_ratio_fit > 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbb21fc-509a-421e-b8c9-cefd8e27e89f",
   "metadata": {},
   "source": [
    "## Updating the predicted I-Y ratios and re-exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe99bc37-ea40-4dda-97fb-7432e4e373ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "iyinfo = pd.read_parquet(\n",
    "    sset.DIR_YPK_INT / \"gdp_gdppc_pop_capital_1950_2020_post_ypk3.parquet\"\n",
    ")\n",
    "iyinfo = iyinfo.merge(\n",
    "    fitted_iy[[\"iy_ratio_fit\"]],\n",
    "    how=\"left\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "iyinfo.loc[\n",
    "    ~pd.isnull(iyinfo.iy_ratio_fit) & pd.isnull(iyinfo.iy_ratio), \"iy_ratio_source\"\n",
    "] = \"hist_reg_project\"\n",
    "\n",
    "iyinfo.loc[(\"SHN\", list(range(1950, 2014))), \"iy_ratio_source\"] = \"hist_reg_project_avg\"\n",
    "iyinfo.to_parquet(\n",
    "    sset.DIR_YPK_INT / \"gdp_gdppc_pop_capital_1950_2020_post_ypk4.parquet\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
